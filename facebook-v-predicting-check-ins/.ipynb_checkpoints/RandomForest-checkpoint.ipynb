{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Loading train data\n",
      "Feature engineering on train\n",
      "Loading test data\n",
      "Feature engineering on test\n",
      "Data prepared in: 0:00:33.236970\n",
      "Row 0 0 0 completed in: 0:00:16.454542\n",
      "Row 0 0 1 completed in: 0:00:31.352561\n",
      "Row 0 0 2 completed in: 0:00:46.768131\n",
      "Row 0 0 3 completed in: 0:01:02.100945\n",
      "Row 0 1 0 completed in: 0:01:14.463173\n",
      "Row 0 1 1 completed in: 0:01:26.364180\n",
      "Row 0 1 2 completed in: 0:01:38.369822\n",
      "Row 0 1 3 completed in: 0:01:50.741009\n",
      "Row 0 2 0 completed in: 0:02:04.608412\n",
      "Row 0 2 1 completed in: 0:02:19.449559\n",
      "Row 0 2 2 completed in: 0:02:34.409976\n",
      "Row 0 2 3 completed in: 0:02:47.865620\n",
      "Row 0 3 0 completed in: 0:03:01.351713\n",
      "Row 0 3 1 completed in: 0:03:15.498297\n",
      "Row 0 3 2 completed in: 0:03:29.990354\n",
      "Row 0 3 3 completed in: 0:03:44.521410\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-839d433bafa1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    339\u001b[0m preds = process_grid(train, test, x_cuts, y_cuts, t_cuts,\n\u001b[0;32m    340\u001b[0m                      \u001b[0mx_border_aug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_border_aug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_aug\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                      fw, th, n_neighbors)\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[0melapsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predictions made in:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0melapsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-839d433bafa1>\u001b[0m in \u001b[0;36mprocess_grid\u001b[1;34m(train, test, x_cuts, y_cuts, t_cuts, x_border_aug, y_border_aug, time_aug, fw, th, n_neighbors)\u001b[0m\n\u001b[0;32m    204\u001b[0m                 \u001b[0mcell_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                 cell_pred = process_one_cell(cell_train, cell_test, \n\u001b[1;32m--> 206\u001b[1;33m                                              fw, th, n_neighbors)\n\u001b[0m\u001b[0;32m    207\u001b[0m                 \u001b[0mpreds_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-839d433bafa1>\u001b[0m in \u001b[0;36mprocess_one_cell\u001b[1;34m(cell_train, cell_test, fw, th, n_neighbors)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# Get predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_preds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# Get top three predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-839d433bafa1>\u001b[0m in \u001b[0;36mget_preds\u001b[1;34m(cell_train, cell_test, n_neighbors)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    545\u001b[0m             delayed(_parallel_helper)(e, 'predict_proba', X,\n\u001b[0;32m    546\u001b[0m                                       check_input=False)\n\u001b[1;32m--> 547\u001b[1;33m             for e in self.estimators_)\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;31m# Reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    725\u001b[0m                 \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m                 \u001b[1;31m# Stop dispatching any new job in the async callback thread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''Inspired by several scripts at:\n",
    "https://www.kaggle.com/c/facebook-v-predicting-check-ins/scripts\n",
    "Special thanks to Sandro for starting the madness. :-)\n",
    "https://www.kaggle.com/svpons/facebook-v-predicting-check-ins/grid-plus-classifier\n",
    "\n",
    "KNN accelerated V3.\n",
    "Numpy argsort replaced with faster JIT compiled function for finding \n",
    "top three predictions.\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import gc\n",
    "from numba import jit\n",
    "\n",
    "# Found at: https://www.kaggle.com/rshekhar2/facebook-v-predicting-check-ins/xgboost-cv-example-with-small-bug\n",
    "def mapkprecision(truthvalues, predictions):\n",
    "    '''\n",
    "    This is a faster implementation of MAP@k valid for numpy arrays.\n",
    "    It is only valid when there is one single truth value. \n",
    "\n",
    "    m ~ number of observations\n",
    "    k ~ MAP at k -- in this case k should equal 3\n",
    "\n",
    "    truthvalues.shape = (m,) \n",
    "    predictions.shape = (m, k)\n",
    "    '''\n",
    "    z = (predictions == truthvalues[:, None]).astype(np.float32)\n",
    "    weights = 1./(np.arange(predictions.shape[1], dtype=np.float32) + 1.)\n",
    "    z = z * weights[None, :]\n",
    "    return np.mean(np.sum(z, axis=1))\n",
    "\n",
    "def load_data(data_name):\n",
    "    types = {'row_id': np.dtype(np.int32),\n",
    "         'x': np.dtype(float),\n",
    "         'y' : np.dtype(float),\n",
    "         'accuracy': np.dtype(np.int16),\n",
    "         'place_id': np.int64,\n",
    "         'time': np.dtype(np.int32)}\n",
    "    df = pd.read_csv(data_name, dtype=types, na_filter=False)\n",
    "    return df\n",
    "\n",
    "def process_one_cell(cell_train, cell_test, fw, th, n_neighbors):\n",
    "    \n",
    "    # Remove infrequent places\n",
    "    places, idx, counts = np.unique(cell_train[:, -1], return_inverse=True, \n",
    "                                    return_counts=True)\n",
    "    count_per_row = counts[idx]\n",
    "    cell_train = cell_train[count_per_row >= th]\n",
    "\n",
    "    # Store row_ids for test\n",
    "    row_ids = cell_test[:, -1].flatten().astype(np.int32)\n",
    "    cell_test = cell_test[:, :-1]\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred, classes = get_preds(cell_train, cell_test, n_neighbors)\n",
    "    \n",
    "    # Get top three predictions\n",
    "    y_pred_labels = top_three_preds(y_pred)\n",
    "    pred_labels = classes[y_pred_labels]\n",
    "    cell_pred = np.column_stack((row_ids, pred_labels)).astype(np.int64) \n",
    "    \n",
    "    return cell_pred\n",
    "    \n",
    "def get_preds(cell_train, cell_test, n_neighbors):\n",
    "    # Preparing data\n",
    "    y = cell_train[:, -1].flatten().astype(np.int64)\n",
    "    X = cell_train[:, :-1]\n",
    "    \n",
    "    #Applying the classifier\n",
    "    cte = 5.7\n",
    "    n_neighbors = int((y.size ** 0.5) / cte)\n",
    "    clf = RandomForestClassifier(100, n_jobs=-1)\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict_proba(cell_test)\n",
    "    return y_pred, clf.classes_\n",
    "    \n",
    "def calculate_distance(distances):\n",
    "    return distances ** -2.2\n",
    "    \n",
    "# Faster than argsort at getting top three predictions\n",
    "@jit(nopython=True)\n",
    "def top_three_preds(preds):\n",
    "    place_count = preds.shape[0]\n",
    "    preds_count = preds.shape[1]\n",
    "    pred_labels = np.zeros((place_count, 3), dtype=np.int32)\n",
    "    for i in range(place_count):\n",
    "        first_place_score = 0\n",
    "        second_place_score = 0\n",
    "        third_place_score = 0\n",
    "        for j in range(preds_count):\n",
    "            this_pred = preds[i,j]\n",
    "            if (this_pred > 0) and (this_pred > third_place_score):\n",
    "                if this_pred > second_place_score:\n",
    "                    pred_labels[i, 2] = pred_labels[i, 1]\n",
    "                    third_place_score = second_place_score\n",
    "                    if this_pred > first_place_score:\n",
    "                        pred_labels[i, 1] = pred_labels[i, 0]\n",
    "                        second_place_score = first_place_score\n",
    "                        first_place_score = this_pred\n",
    "                        pred_labels[i, 0] = j\n",
    "                    else:\n",
    "                        second_place_score = this_pred\n",
    "                        pred_labels[i, 1] = j\n",
    "                else:\n",
    "                    third_place_score = this_pred\n",
    "                    pred_labels[i, 2] = j\n",
    "    return pred_labels\n",
    "    \n",
    "# Precompute the trig values\n",
    "def time_trig(max_time):\n",
    "    time_array = np.linspace(0, 2*np.pi, max_time)\n",
    "    sin_values = np.sin(time_array)\n",
    "    cos_values = np.cos(time_array)\n",
    "    return (sin_values, cos_values)\n",
    "    \n",
    "# Generate a dictionary of the time limits so it doesn't have to be \n",
    "# recalculated each loop\n",
    "def create_time_dict(t_cuts, time_mod, time_weight, time_aug):\n",
    "    \n",
    "    t_slice = 24 / t_cuts\n",
    "    time_dict = dict()\n",
    "    trig_array = time_trig(time_mod)\n",
    "    for t in range(t_cuts):\n",
    "        \n",
    "        t_min = int(t * t_slice * 12)\n",
    "        t_max = int((t + 1) * t_slice * 12 - 1)\n",
    "        sin_t_start = trig_array[0][t_min] * time_weight\n",
    "        sin_t_stop = trig_array[0][t_max] * time_weight\n",
    "        cos_t_start = trig_array[1][t_min] * time_weight\n",
    "        cos_t_stop = trig_array[1][t_max] * time_weight\n",
    "        sin_t_min = min((sin_t_start, sin_t_stop))\n",
    "        sin_t_max = max((sin_t_start, sin_t_stop))\n",
    "        cos_t_min = min((cos_t_start, cos_t_stop))\n",
    "        cos_t_max = max((cos_t_start, cos_t_stop))\n",
    "        time_dict[t] = [sin_t_min, sin_t_max, cos_t_min, cos_t_max]\n",
    "\n",
    "        t_min = int((t * t_slice - time_aug) * 12)%time_mod\n",
    "        t_max = int(((t + 1) * t_slice + time_aug)* 12 - 1)%time_mod\n",
    "        sin_t_start = trig_array[0][t_min] * time_weight\n",
    "        sin_t_stop = trig_array[0][t_max] * time_weight\n",
    "        cos_t_start = trig_array[1][t_min] * time_weight\n",
    "        cos_t_stop = trig_array[1][t_max] * time_weight\n",
    "        sin_t_min = min((sin_t_start, sin_t_stop, sin_t_min))\n",
    "        sin_t_max = max((sin_t_start, sin_t_stop, sin_t_max))\n",
    "        cos_t_min = min((cos_t_start, cos_t_stop, cos_t_min))\n",
    "        cos_t_max = max((cos_t_start, cos_t_stop, cos_t_max))\n",
    "        time_dict[t] += [sin_t_min, sin_t_max, cos_t_min, cos_t_max]\n",
    "        \n",
    "    return time_dict\n",
    "\n",
    "@jit\n",
    "def apply_mask(data, feature, mask_min, mask_max):\n",
    "    mask = (data[:, feature] >= mask_min)\n",
    "    mask = mask & (data[:, feature] < mask_max)      \n",
    "    return data[mask]    \n",
    "\n",
    "def process_grid(train, test, x_cuts, y_cuts, t_cuts,\n",
    "                 x_border_aug, y_border_aug, time_aug, fw, th, n_neighbors):\n",
    "    preds_list = []\n",
    "    x_slice = train[:, 0].max() / x_cuts\n",
    "    y_slice = train[:, 1].max() / y_cuts\n",
    "    time_mod = 288\n",
    "    time_weight = fw[2]\n",
    "    time_dict = create_time_dict(t_cuts, time_mod, time_weight, time_aug)\n",
    "\n",
    "    for i in range(x_cuts):\n",
    "        row_start_time = time.time()\n",
    "        x_min = x_slice * i\n",
    "        x_max = x_slice * (i+1)\n",
    "        x_max += int((i+1) == x_cuts) # expand edge at end\n",
    "\n",
    "        col_test = apply_mask(test, 0, x_min, x_max)\n",
    "        x_min -= x_border_aug\n",
    "        x_max += x_border_aug\n",
    "        col_train = apply_mask(train, 0, x_min, x_max)\n",
    "\n",
    "        for j in range(y_cuts):\n",
    "            y_min = y_slice * j\n",
    "            y_max = y_slice * (j+1)\n",
    "            y_max += int((j+1) == y_cuts) # expand edge at end\n",
    "\n",
    "            row_test = apply_mask(col_test, 1, y_min, y_max)\n",
    "            y_min -= y_border_aug\n",
    "            y_max += y_border_aug\n",
    "            row_train = apply_mask(col_train, 1, y_min, y_max)\n",
    "\n",
    "            for t in range(t_cuts):\n",
    "                #print(df_row_test.shape, df_row_train.shape)\n",
    "                t_lim = time_dict[t]\n",
    "                mask = (row_test[:, 2] >= t_lim[0])\n",
    "                mask = mask & (row_test[:, 2] <= t_lim[1])\n",
    "                mask = mask & (row_test[:, 3] >= t_lim[2])\n",
    "                mask = mask & (row_test[:, 3] <= t_lim[3])\n",
    "                cell_test = row_test[mask]\n",
    "                mask = (row_train[:, 2] >= t_lim[4])\n",
    "                mask = mask & (row_train[:, 2] <= t_lim[5])\n",
    "                mask = mask & (row_train[:, 3] >= t_lim[6])\n",
    "                mask = mask & (row_train[:, 3] <= t_lim[7])\n",
    "                cell_train = row_train[mask]\n",
    "                cell_pred = process_one_cell(cell_train, cell_test, \n",
    "                                             fw, th, n_neighbors)\n",
    "                preds_list.append(cell_pred)\n",
    "        elapsed = (time.time() - row_start_time)\n",
    "        print('Row', i, 'completed in:', timedelta(seconds=elapsed))\n",
    "    preds = np.vstack(preds_list)\n",
    "    return preds\n",
    "\n",
    "# Thank you Alex!\n",
    "# From: https://www.kaggle.com/drarfc/facebook-v-predicting-check-ins/fastest-way-to-write-the-csv\n",
    "def generate_submission(preds):    \n",
    "    print('Writing submission file')\n",
    "    with open('KNN_submission.csv', \"w\") as out:\n",
    "        out.write(\"row_id,place_id\\n\")\n",
    "        rows = ['']*8607230\n",
    "        n=0\n",
    "        for num in range(8607230):\n",
    "            rows[n]='%d,%d %d %d\\n' % (preds[num,0],preds[num,1],preds[num,2],preds[num,3])\n",
    "            n=n+1\n",
    "        out.writelines(rows)\n",
    "\n",
    "def validation_split(df, val_start_day):\n",
    "    day = df['time']//1440\n",
    "    df_val = df.loc[(day>=val_start_day)].copy()\n",
    "    df = df.loc[(day<val_start_day)].copy()\n",
    "    return df, df_val\n",
    "    \n",
    "def remove_infrequent_places_df(df, th=5):\n",
    "    place_counts = df.place_id.value_counts()\n",
    "    mask = (place_counts[df.place_id.values] >= th).values\n",
    "    df = df[mask]\n",
    "    return df\n",
    "\n",
    "def prepare_data(datapath, val_start_day, train_columns, test_columns, \n",
    "                 fw, th, off):\n",
    "    val_label = None\n",
    "    print('Loading train data')\n",
    "    df_train = load_data(datapath + 'train.csv')\n",
    "    if val_start_day > 0:\n",
    "        # Create validation data\n",
    "        df_train, df_test = validation_split(df_train, val_start_day)\n",
    "        val_label = df_test['place_id'] \n",
    "        df_test.drop(['place_id'], axis=1, inplace=True)    \n",
    "    print('Feature engineering on train')\n",
    "    df_train.drop(['row_id'], axis=1, inplace=True)\n",
    "    df_train = remove_infrequent_places_df(df_train, th)\n",
    "    gc.collect()\n",
    "    df_train = feature_engineering(df_train, off)\n",
    "    df_train = apply_weights(df_train, fw)\n",
    "    # reorder the columns so the place id is at the end\n",
    "    train = df_train[train_columns].values\n",
    "    del df_train\n",
    "    gc.collect()\n",
    "    if val_start_day == 0:\n",
    "        print('Loading test data')\n",
    "        df_test = load_data(datapath + 'test.csv') \n",
    "    print('Feature engineering on test')\n",
    "    df_test = feature_engineering(df_test, off)\n",
    "    df_test = apply_weights(df_test, fw)\n",
    "    test = df_test[test_columns].values\n",
    "    del df_test\n",
    "    gc.collect()\n",
    "    return train, test, val_label\n",
    "        \n",
    "def apply_weights(df, fw):\n",
    "    df['accuracy'] *= fw[0]\n",
    "    df['day_of_year_sin'] *= fw[1]\n",
    "    df['day_of_year_cos'] *= fw[1]\n",
    "    df['minute_sin'] *= fw[2]\n",
    "    df['minute_cos'] *= fw[2]\n",
    "    df['weekday_sin'] *= fw[3]\n",
    "    df['weekday_cos'] *= fw[3]\n",
    "    df.x *= fw[4]\n",
    "    df.y *= fw[5]\n",
    "    df['year'] *= fw[6]\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df, off):\n",
    "    minute =((df[\"time\"]+off[0])//5)%288\n",
    "    trig_arrays = time_trig(288)\n",
    "    df['minute_sin'] = trig_arrays[0][minute]\n",
    "    df['minute_cos'] = trig_arrays[1][minute]\n",
    "    del minute\n",
    "    day = ((df['time']+off[1])//1440)%365\n",
    "    trig_arrays = time_trig(365)\n",
    "    df['day_of_year_sin'] = trig_arrays[0][day]\n",
    "    df['day_of_year_cos'] = trig_arrays[1][day]\n",
    "    del day\n",
    "    weekday = ((df['time']+off[2])//1440)%7\n",
    "    trig_arrays = time_trig(7)\n",
    "    df['weekday_sin'] = trig_arrays[0][weekday]\n",
    "    df['weekday_cos'] = trig_arrays[1][weekday]\n",
    "    del weekday\n",
    "    df['year'] = (df['time']//525600).astype(float)\n",
    "    df.drop(['time'], axis=1, inplace=True)\n",
    "    df['accuracy'] = np.log10(df['accuracy']).astype(float)\n",
    "    return df\n",
    "    \n",
    "print('Starting...')\n",
    "start_time = time.time()\n",
    "# Global variables\n",
    "datapath = ''\n",
    "# Change val_start_day to zero to generate predictions\n",
    "val_start_day = 0 # Day at which to cut validation\n",
    "th = 5 # Threshold at which to cut places from train\n",
    "\n",
    "#fw = [127., 33.6, 64.4, 26., 2300, 5625, 55.6]\n",
    "#fw = [127., 33.6, 64.1, 26., 2300, 5625, 55.8]\n",
    "fw = [127., 33.4, 63.6, 26., 2300, 5620, 56.4]\n",
    "\n",
    "off = [444, 931, 421]\n",
    "\n",
    "# Defining the size of the grid\n",
    "x_cuts = 12 # number of cuts along x \n",
    "y_cuts = 25 # number of cuts along y\n",
    "#TODO: More general solution for t_cuts. For now must be 4.\n",
    "t_cuts = 4 # number of cuts along time. \n",
    "x_border_aug = 0.0052 * fw[4] # expansion of x border on train \n",
    "y_border_aug = 0.0042 * fw[5] # expansion of y border on train\n",
    "time_aug = 2.5\n",
    "n_neighbors = 0\n",
    "columns = ['x', 'y', 'minute_sin', 'minute_cos', 'accuracy',\n",
    "           'day_of_year_sin', 'day_of_year_cos', \n",
    "           'weekday_sin', 'weekday_cos', 'year']\n",
    "train_columns = columns + ['place_id']\n",
    "test_columns  = columns + ['row_id']\n",
    "\n",
    "train, test, val_label = prepare_data(datapath, val_start_day,\n",
    "                                      train_columns, test_columns, fw, th, off)\n",
    "\n",
    "elapsed = (time.time() - start_time)\n",
    "print('Data prepared in:', timedelta(seconds=elapsed))\n",
    "    \n",
    "preds = process_grid(train, test, x_cuts, y_cuts, t_cuts,\n",
    "                     x_border_aug, y_border_aug, time_aug, \n",
    "                     fw, th, n_neighbors)\n",
    "elapsed = (time.time() - start_time)\n",
    "print('Predictions made in:', timedelta(seconds=elapsed))\n",
    "\n",
    "if val_start_day > 0:\n",
    "    preds = preds[preds[:, 0] > 0] # only use rows predicted\n",
    "    labels = val_label.loc[preds[:, 0]].values\n",
    "    score = mapkprecision(labels, preds[:, 1:])\n",
    "    print('Final score:', score)\n",
    "else:\n",
    "    print('Pred shape:', preds.shape)\n",
    "    generate_submission(preds)\n",
    "elapsed = (time.time() - start_time)\n",
    "print('Task completed in:', timedelta(seconds=elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
