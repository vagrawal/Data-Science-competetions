{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating wrong models. They are just useful to get this job :) ... done\n",
      "Done  0\n",
      "Done  1\n",
      "Done  2\n",
      "Done  3\n",
      "Done  4\n",
      "Done  5\n",
      "Done  6\n",
      "Done  7\n",
      "Done  8\n",
      "Done  9\n",
      "Done  10\n",
      "Done  11\n",
      "Done  12\n",
      "Done  13\n",
      "Done  14\n",
      "Done  15\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "#COMPETITION NAME (the 'Competition'): Facebook V: Predicting Check Ins \n",
    "#COMPETITION SPONSOR: Facebook\n",
    "#COMPETITION WEBSITE: https://www.kaggle.com/c/facebook-v-predicting-check-ins\n",
    "\n",
    "'''Partially based on several scripts:\n",
    "https://www.kaggle.com/c/facebook-v-predicting-check-ins/scripts\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#print('\tReading train.csv')\n",
    "df_train = pd.read_csv('train.csv',\n",
    "                        usecols=['row_id','x','y','time','place_id','accuracy'], \n",
    "                        index_col = 0)\n",
    "#print('\tReading test.csv')\n",
    "df_test = pd.read_csv('test.csv',\n",
    "                        usecols=['row_id','x','y','time','accuracy'],\n",
    "                        index_col = 0)\n",
    "\n",
    "#print('Feature Augmentation')\n",
    "minute = df_train.time%60\n",
    "df_train['hour'] = df_train['time']//60\n",
    "df_train.drop(['time'], axis=1, inplace=True)\n",
    "df_train['weekday'] = df_train['hour']//24\n",
    "df_train['month'] = df_train['weekday']//30\n",
    "df_train['year'] = (df_train['weekday']//365+1)*10.0\n",
    "df_train['hour'] = ((df_train['hour']%24+1)+minute/60.0)*4.0\n",
    "df_train['weekday'] = (df_train['weekday']%7+1)*3.0\n",
    "df_train['month'] = (df_train['month']%12+1)*2.0\n",
    "df_train['accuracy'] = np.log10(df_train['accuracy'])*10.0\n",
    "\n",
    "minute = df_test['time']%60\n",
    "df_test['hour'] = df_test['time']//60\n",
    "df_test.drop(['time'], axis=1, inplace=True)\n",
    "df_test['weekday'] = df_test['hour']//24\n",
    "df_test['month'] = df_test['weekday']//30\n",
    "df_test['year'] = (df_test['weekday']//365+1)*10.0\n",
    "df_test['hour'] = ((df_test['hour']%24+1)+minute/60.0)*4.0\n",
    "df_test['weekday'] = (df_test['weekday']%7+1)*3.0\n",
    "df_test['month'] = (df_test['month']%12+1)*2.0\n",
    "df_test['accuracy'] = np.log10(df_test['accuracy'])*10.0\n",
    "\n",
    "# add data for periodic time that hit the boundary\n",
    "pd.options.mode.chained_assignment = None\n",
    "add_data = df_train[df_train.hour<6]\n",
    "add_data.hour = add_data.hour+96\n",
    "df_train = df_train.append(add_data)\n",
    "\n",
    "add_data = df_train[df_train.hour>98]\n",
    "add_data.hour = add_data.hour-96\n",
    "df_train = df_train.append(add_data)\n",
    "\n",
    "print('Generating wrong models. They are just useful to get this job :) ... done')\n",
    "\n",
    "def calculate_distance(distances):\n",
    "    return distances ** -2\n",
    "\n",
    "def process_one_cell(df_cell_train, df_cell_test):\n",
    "    \n",
    "    #Working on df_train\n",
    "    place_counts = df_cell_train.place_id.value_counts()\n",
    "    mask = (place_counts[df_cell_train.place_id.values] >= 8).values\n",
    "    df_cell_train = df_cell_train.loc[mask]\n",
    "    \n",
    "    #Working on df_test\n",
    "    row_ids = df_cell_test.index\n",
    "    \n",
    "    #Feature engineering on x and y\n",
    "    df_cell_train.loc[:,'x'] *= 500.0\n",
    "    df_cell_train.loc[:,'y'] *= 1000.0\n",
    "    df_cell_test.loc[:,'x'] *= 500.0\n",
    "    df_cell_test.loc[:,'y'] *= 1000.0\n",
    "    \n",
    "    #Preparing data\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df_cell_train.place_id.values)\n",
    "    best_k=np.floor(np.sqrt(y.size)/5)\n",
    "    X = df_cell_train.drop(['place_id'], axis=1).values\n",
    "    X_test = df_cell_test.values\n",
    "\n",
    "    #Applying the classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=best_k.astype(int), weights=calculate_distance,metric='manhattan',n_jobs=-1)\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    pred_labels = le.inverse_transform(np.argsort(y_pred, axis=1)[:,::-1][:,:3]) \n",
    "    \n",
    "    return pred_labels, row_ids\n",
    "   \n",
    "def process_grid(df_train, df_test):\n",
    "    \"\"\"\n",
    "    Iterates over all grid cells, aggregates the results\n",
    "    \"\"\"\n",
    "    size = 10.0\n",
    "    x_step = 0.5\n",
    "    y_step = 0.25\n",
    "    \n",
    "    x_border_augment = 0.2  \n",
    "    y_border_augment = 0.1\n",
    "    \n",
    "    preds = np.zeros((df_test.shape[0], 3), dtype=int)\n",
    "\n",
    "    for i in range((int)(size/x_step)):\n",
    "        \n",
    "        print(\"Done \", i)\n",
    "        \n",
    "        x_min = x_step * i\n",
    "        x_max = x_step * (i+1)\n",
    "        x_min = round(x_min, 4)\n",
    "        x_max = round(x_max, 4) \n",
    "        if x_max == size:\n",
    "            x_max = x_max + 0.001\n",
    "            \n",
    "        df_col_train = df_train[(df_train['x'] >= x_min-x_border_augment) & (df_train['x'] < x_max+x_border_augment)]\n",
    "        df_col_test = df_test[(df_test['x'] >= x_min) & (df_test['x'] < x_max)]\n",
    "\n",
    "        for j in range((int)(size/y_step)):\n",
    "            y_min = y_step * j\n",
    "            y_max = y_step * (j+1)\n",
    "            y_min = round(y_min, 4)\n",
    "            y_max = round(y_max, 4)   \n",
    "            if y_max == size:\n",
    "                y_max = y_max + 0.001\n",
    "                \n",
    "            df_cell_train = df_col_train[(df_col_train['y'] >= y_min-y_border_augment) & (df_col_train['y'] < y_max+y_border_augment)]\n",
    "            df_cell_test = df_col_test[(df_col_test['y'] >= y_min) & (df_col_test['y'] < y_max)]\n",
    "            \n",
    "            #Applying classifier to one grid cell\n",
    "            pred_labels, row_ids = process_one_cell(df_cell_train, df_cell_test)\n",
    "\n",
    "            #Updating predictions\n",
    "            preds[row_ids] = pred_labels\n",
    "    \n",
    "    return preds\n",
    "\n",
    "def generate_sub(preds):    \n",
    "    #print('Writing submission file')\n",
    "    #Auxiliary dataframe with the 3 best predictions for each sample\n",
    "    df_aux = pd.DataFrame(preds, dtype=str, columns=['l1', 'l2', 'l3'])\n",
    "    #Concatenating the 3 predictions for each sample\n",
    "    ds_sub = df_aux.l1.str.cat([df_aux.l2, df_aux.l3], sep=' ')\n",
    "    \n",
    "    #Writting to csv\n",
    "    ds_sub.name = 'place_id'\n",
    "    ds_sub.to_csv('submission_sample2.csv', index=True, header=True, index_label='row_id')\n",
    "\n",
    "preds=process_grid(df_train, df_test)\n",
    "\n",
    "del df_train, df_test\n",
    "\n",
    "generate_sub(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
