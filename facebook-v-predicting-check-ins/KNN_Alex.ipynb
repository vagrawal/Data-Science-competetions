{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Feature engineering on train\n",
      "Feature engineering on test\n",
      "Data prepared in: 0:00:41.193897\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "#COMPETITION NAME (the 'Competition'): Facebook V: Predicting Check Ins \n",
    "#COMPETITION SPONSOR: Facebook\n",
    "#COMPETITION WEBSITE: https://www.kaggle.com/c/facebook-v-predicting-check-ins\n",
    "\n",
    "'''Inspired by several scripts at:\n",
    "https://www.kaggle.com/c/facebook-v-predicting-check-ins/scripts\n",
    "Special thanks to\n",
    "Michael Hartman\n",
    "https://www.kaggle.com/zeroblue/facebook-v-predicting-check-ins/mad-scripts-battle-z/\n",
    "Sandro for starting the madness. :-)\n",
    "https://www.kaggle.com/svpons/facebook-v-predicting-check-ins/grid-plus-classifier\n",
    "ZFTurbo for the grid concept\n",
    "https://www.kaggle.com/zfturbo/facebook-v-predicting-check-ins/msb-with-validation\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import gc\n",
    "\n",
    "# Found at: https://www.kaggle.com/rshekhar2/facebook-v-predicting-check-ins/xgboost-cv-example-with-small-bug\n",
    "def mapkprecision(truthvalues, predictions):\n",
    "    '''\n",
    "    This is a faster implementation of MAP@k valid for numpy arrays.\n",
    "    It is only valid when there is one single truth value. \n",
    "\n",
    "    m ~ number of observations\n",
    "    k ~ MAP at k -- in this case k should equal 3\n",
    "\n",
    "    truthvalues.shape = (m,) \n",
    "    predictions.shape = (m, k)\n",
    "    '''\n",
    "    z = (predictions == truthvalues[:, None]).astype(np.float32)\n",
    "    weights = 1./(np.arange(predictions.shape[1], dtype=np.float32) + 1.)\n",
    "    z = z * weights[None, :]\n",
    "    return np.mean(np.sum(z, axis=1))\n",
    "\n",
    "def load_data(data_name):\n",
    "    types = {'row_id': np.dtype(np.int32),\n",
    "         'x': np.dtype(float),\n",
    "         'y' : np.dtype(float),\n",
    "         'accuracy': np.dtype(np.int16),\n",
    "         'place_id': np.int64,\n",
    "         'time': np.dtype(np.int32)}\n",
    "    df = pd.read_csv(data_name, dtype=types, index_col = 0, na_filter=False)\n",
    "    return df\n",
    "\n",
    "def process_one_cell(df_cell_train, df_cell_test, fw, th, n_neighbors):\n",
    "    \n",
    "    # Remove infrequent places\n",
    "    df_cell_train = remove_infrequent_places(df_cell_train, th).copy()\n",
    "    \n",
    "    # Store row_ids for test\n",
    "    row_ids = df_cell_test.index\n",
    "    \n",
    "    # Preparing data\n",
    "    y = df_cell_train.place_id.values\n",
    "    X = df_cell_train.drop(['place_id'], axis=1).values\n",
    "    \n",
    "    #Applying the classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=np.floor(np.sqrt(y.size)/5.83).astype(int),\n",
    "                            weights=calculate_distance, p=1, \n",
    "                            n_jobs=-1, leaf_size=20)\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict_proba(df_cell_test.values)\n",
    "    y_pred_labels = np.argsort(y_pred, axis=1)[:,:-4:-1]\n",
    "    pred_labels = clf.classes_[y_pred_labels]\n",
    "    cell_pred = np.column_stack((row_ids, pred_labels)).astype(np.int64) \n",
    "    \n",
    "    return cell_pred\n",
    "    \n",
    "def calculate_distance(distances):\n",
    "    return distances ** -2.2\n",
    "    \n",
    "# Generate a dictionary of the time limits so it doesn't have to be \n",
    "# recalculated each loop\n",
    "def create_time_dict(t_cuts, time_factor, time_aug):\n",
    "    \n",
    "    t_slice = 24 / t_cuts\n",
    "    time_dict = dict()\n",
    "    for t in range(t_cuts):\n",
    "        \n",
    "        t_min = 2 * np.pi * (t * t_slice * 12 / 288)\n",
    "        t_max = 2 * np.pi * (((t + 1) * t_slice * 12 - 1) / 288)\n",
    "        sin_t_start = np.round(np.sin(t_min)+1, 4) * time_factor\n",
    "        sin_t_stop = np.round(np.sin(t_max)+1, 4) * time_factor\n",
    "        cos_t_start = np.round(np.cos(t_min)+1, 4) * time_factor\n",
    "        cos_t_stop = np.round(np.cos(t_max)+1, 4) * time_factor\n",
    "        #print(t, (sin_t_start, sin_t_stop, cos_t_start, cos_t_stop))\n",
    "        sin_t_min = min((sin_t_start, sin_t_stop))\n",
    "        sin_t_max = max((sin_t_start, sin_t_stop))\n",
    "        cos_t_min = min((cos_t_start, cos_t_stop))\n",
    "        cos_t_max = max((cos_t_start, cos_t_stop))\n",
    "\n",
    "        time_dict[t] = [sin_t_min, sin_t_max, cos_t_min, cos_t_max]\n",
    "        t_min = 2 * np.pi * ((t * t_slice - time_aug) * 12 / 288)\n",
    "        t_max = 2 * np.pi * ((((t + 1) * t_slice + time_aug)* 12 - 1) / 288)\n",
    "        sin_t_start = np.round(np.sin(t_min)+1, 4) * time_factor\n",
    "        sin_t_stop = np.round(np.sin(t_max)+1, 4) * time_factor\n",
    "        cos_t_start = np.round(np.cos(t_min)+1, 4) * time_factor\n",
    "        cos_t_stop = np.round(np.cos(t_max)+1, 4) * time_factor\n",
    "        sin_t_min = min((sin_t_start, sin_t_stop, sin_t_min))\n",
    "        sin_t_max = max((sin_t_start, sin_t_stop, sin_t_max))\n",
    "        cos_t_min = min((cos_t_start, cos_t_stop, cos_t_min))\n",
    "        cos_t_max = max((cos_t_start, cos_t_stop, cos_t_max))\n",
    "        time_dict[t] += [sin_t_min, sin_t_max, cos_t_min, cos_t_max]\n",
    "        \n",
    "    return time_dict\n",
    "\n",
    "def process_grid(df_train, df_test, x_cuts, y_cuts, t_cuts,\n",
    "                 x_border_aug, y_border_aug, time_aug, fw, th, n_neighbors):\n",
    "    preds_list = []\n",
    "    x_slice = df_train['x'].max() / x_cuts\n",
    "    y_slice = df_train['y'].max() / y_cuts\n",
    "    time_max = df_train['minute_sin'].max()\n",
    "    time_factor = time_max / 2\n",
    "    time_dict = create_time_dict(t_cuts, time_factor, time_aug)\n",
    "\n",
    "    for i in range(x_cuts):\n",
    "        row_start_time = time.time()\n",
    "        x_min = x_slice * i\n",
    "        x_max = x_slice * (i+1)\n",
    "        x_max += int((i+1) == x_cuts) # expand edge at end\n",
    "\n",
    "        mask = (df_test['x'] >= x_min)\n",
    "        mask = mask & (df_test['x'] < x_max)      \n",
    "        df_col_test = df_test[mask]\n",
    "        x_min -= x_border_aug\n",
    "        x_max += x_border_aug\n",
    "        mask = (df_train['x'] >= x_min)\n",
    "        mask = mask & (df_train['x'] < x_max)\n",
    "        df_col_train = df_train[mask]\n",
    "\n",
    "        for j in range(y_cuts):\n",
    "            y_min = y_slice * j\n",
    "            y_max = y_slice * (j+1)\n",
    "            y_max += int((j+1) == y_cuts) # expand edge at end\n",
    "\n",
    "            mask = (df_col_test['y'] >= y_min)\n",
    "            mask= mask & (df_col_test['y'] < y_max)\n",
    "            df_row_test = df_col_test[mask]\n",
    "            y_min -= y_border_aug\n",
    "            y_max += y_border_aug\n",
    "            mask = (df_col_train['y'] >= y_min)\n",
    "            mask = mask & (df_col_train['y'] < y_max)\n",
    "            df_row_train = df_col_train[mask]\n",
    "\n",
    "            for t in range(t_cuts):\n",
    "                #print(df_row_test.shape, df_row_train.shape)\n",
    "                t_lim = time_dict[t]\n",
    "                mask = df_row_test['minute_sin'].between(t_lim[0], t_lim[1])\n",
    "                mask = mask & df_row_test['minute_cos'].between(t_lim[2], t_lim[3])\n",
    "                df_cell_test = df_row_test[mask].copy()\n",
    "                mask = df_row_train['minute_sin'].between(t_lim[4], t_lim[5])\n",
    "                mask = mask & df_row_train['minute_cos'].between(t_lim[6], t_lim[7])\n",
    "                df_cell_train = df_row_train[mask].copy()\n",
    "                cell_pred = process_one_cell(df_cell_train.copy(), \n",
    "                                             df_cell_test.copy(), \n",
    "                                             fw, th, n_neighbors)\n",
    "                preds_list.append(cell_pred)\n",
    "        elapsed = (time.time() - row_start_time)\n",
    "        print('Row', i, 'completed in:', timedelta(seconds=elapsed))\n",
    "    preds = np.vstack(preds_list)\n",
    "    return preds\n",
    "\n",
    "# From: https://www.kaggle.com/drarfc/facebook-v-predicting-check-ins/fastest-way-to-write-the-csv\n",
    "def generate_submission(preds):    \n",
    "    print('Writing submission file')\n",
    "    with open('KNN_submission.csv', \"w\") as out:\n",
    "        out.write(\"row_id,place_id\\n\")\n",
    "        rows = ['']*preds.shape[0]\n",
    "        for num in range(preds.shape[0]):\n",
    "            rows[num]='%d,%d %d %d\\n' % (preds[num,0],preds[num,1],preds[num,2],preds[num,3])\n",
    "        out.writelines(rows)\n",
    "\n",
    "def validation_split(df, val_start_day):\n",
    "    day = df['time']//1440\n",
    "    df_val = df.loc[(day>=val_start_day)].copy()\n",
    "    df = df.loc[(day<val_start_day)].copy()\n",
    "    return df, df_val\n",
    "\n",
    "def remove_infrequent_places(df, th):\n",
    "    place_counts = df.place_id.value_counts()\n",
    "    mask = (place_counts[df.place_id.values] >= th).values\n",
    "    df = df.loc[mask]\n",
    "    return df\n",
    "    \n",
    "def prepare_data(datapath, val_start_day):\n",
    "    val_label = None\n",
    "    df_train = load_data(datapath + 'train.csv')\n",
    "    if val_start_day > 0:\n",
    "        # Create validation data\n",
    "        df_train, df_test = validation_split(df_train, val_start_day)\n",
    "        val_label = df_test['place_id']\n",
    "        df_test.drop(['place_id'], axis=1, inplace=True)\n",
    "        print('Feature engineering on train')\n",
    "        df_train = feature_engineering(df_train)\n",
    "        print('Feature engineering on validation')\n",
    "        df_test = feature_engineering(df_test)\n",
    "    else:\n",
    "        print('Feature engineering on train')\n",
    "        df_train = feature_engineering(df_train)\n",
    "        df_test = load_data(datapath + 'test.csv') \n",
    "        print('Feature engineering on test')\n",
    "        df_test = feature_engineering(df_test)\n",
    "    df_train = apply_weights(df_train, fw)\n",
    "    df_test = apply_weights(df_test, fw)\n",
    "    return df_train, df_test, val_label\n",
    "        \n",
    "\n",
    "def apply_weights(df, fw):\n",
    "    df['accuracy'] *= fw[0]\n",
    "    df['day_of_year_sin'] *= fw[1]\n",
    "    df['day_of_year_cos'] *= fw[1]\n",
    "    df['minute_sin'] *= fw[2]\n",
    "    df['minute_cos'] *= fw[2]\n",
    "    df['weekday_sin'] *= fw[3]\n",
    "    df['weekday_cos'] *= fw[3]\n",
    "    df.x *= fw[4]\n",
    "    df.y *= fw[5]\n",
    "    df['year'] *= fw[6]\n",
    "    return df\n",
    "    \n",
    "def feature_engineering(df):\n",
    "    #periodic features from 1\n",
    "    minute = 2*np.pi*(((df[\"time\"]//5)+1)%288)/288\n",
    "    df['minute_sin'] = (np.sin(minute)+1).round(4)\n",
    "    df['minute_cos'] = (np.cos(minute)+1).round(4)\n",
    "    del minute\n",
    "    day = 2*np.pi*(((df['time']//1440)+1)%365)/365\n",
    "    df['day_of_year_sin'] = (np.sin(day)+1).round(4)\n",
    "    df['day_of_year_cos'] = (np.cos(day)+1).round(4)\n",
    "    del day\n",
    "    weekday = 2*np.pi*(((df['time']//1440)+1)%7)/7\n",
    "    df['weekday_sin'] = (np.sin(weekday)+1).round(4)\n",
    "    df['weekday_cos'] = (np.cos(weekday)+1).round(4)\n",
    "    del weekday\n",
    "    df['year'] = (df['time'])//525600\n",
    "    df.drop(['time'], axis=1, inplace=True)\n",
    "    df['accuracy'] = np.log10(df['accuracy'])\n",
    "    return df\n",
    "    \n",
    "print('Starting...')\n",
    "start_time = time.time()\n",
    "# Global variables\n",
    "datapath = './'\n",
    "# Change val_start_day to zero to generate predictions\n",
    "val_start_day = 0 #change to 455 in order to activate validation\n",
    "th = 6 # Threshold at which to cut places from train\n",
    "fw = [0.6, 0.32935, 0.56515, 0.2670, 22, 52, 0.51785]\n",
    "\n",
    "# Defining the size of the grid\n",
    "x_cuts = 10 # number of cuts along x \n",
    "y_cuts = 25 # number of cuts along y\n",
    "#TODO: More general solution for t_cuts. For now must be 4.\n",
    "t_cuts = 4 # number of cuts along time. \n",
    "x_border_aug = 0.04 # expansion of x border on train \n",
    "y_border_aug = 0.015 # expansion of y border on train\n",
    "time_aug = 2\n",
    "n_neighbors = 37\n",
    "\n",
    "df_train, df_test, val_label = prepare_data(datapath, val_start_day)\n",
    "gc.collect()\n",
    "\n",
    "elapsed = (time.time() - start_time)\n",
    "print('Data prepared in:', timedelta(seconds=elapsed))\n",
    "    \n",
    "preds = process_grid(df_train, df_test, x_cuts, y_cuts, t_cuts,\n",
    "                     x_border_aug, y_border_aug, time_aug, \n",
    "                     fw, th, n_neighbors)\n",
    "elapsed = (time.time() - start_time)\n",
    "print('Predictions made in:', timedelta(seconds=elapsed))\n",
    "\n",
    "#del df_train, df_test\n",
    "\n",
    "if val_start_day > 0:\n",
    "    preds = preds[preds[:, 0] > 0] # only use rows predicted\n",
    "    labels = val_label.loc[preds[:, 0]].values\n",
    "    score = mapkprecision(labels, preds[:, 1:])\n",
    "    print('Final score:', score)\n",
    "else:\n",
    "    generate_submission(preds)\n",
    "elapsed = (time.time() - start_time)\n",
    "print('Task completed in:', timedelta(seconds=elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
