{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GRID K520 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import datetime\n",
    "import time\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, MaxoutDense\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, RemoteMonitor\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 128, 128\n",
    "nfolds = 10\n",
    "\n",
    "def get_im_cv2(path, img_rows, img_cols):\n",
    "    img = cv2.imread(path, 0)\n",
    "    resized = cv2.resize(img, (img_cols, img_rows), cv2.INTER_LINEAR)\n",
    "    return resized\n",
    "\n",
    "\n",
    "def load_train(img_rows, img_cols):\n",
    "    X_train = np.array()\n",
    "    X_train_id = []\n",
    "    mask_train = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Read train images')\n",
    "    files = glob.glob(\"train/*[0-9].tif\")\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = get_im_cv2(fl, img_rows, img_cols)\n",
    "        X_train.append(img)\n",
    "        X_train_id.append(flbase[:-4])\n",
    "        mask_path = \"train/\" + flbase[:-4] + \"_mask.tif\"\n",
    "        mask = get_im_cv2(mask_path, img_rows, img_cols)\n",
    "        mask_train.append(mask)\n",
    "\n",
    "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return np.array(X_train), np.array(mask_train), np.array(X_train_id)\n",
    "\n",
    "\n",
    "def load_test(img_rows, img_cols):\n",
    "    print('Read test images')\n",
    "    files = glob.glob(\"test/*[0-9].tif\")\n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = get_im_cv2(fl, img_rows, img_cols)\n",
    "        X_test.append(img)\n",
    "        X_test_id.append(flbase[:-4])\n",
    "        total += 1\n",
    "\n",
    "    print('Read test data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return np.array(X_test), np.array(X_test_id)\n",
    "\n",
    "\n",
    "def rle_encode(img, order='F'):\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []\n",
    "    r = 0\n",
    "    pos = 1\n",
    "    for c in bytes:\n",
    "        if c == 0:\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "\n",
    "    z = ''\n",
    "    for rr in runs:\n",
    "        z += str(rr[0]) + ' ' + str(rr[1]) + ' '\n",
    "    return z[:-1]\n",
    "\n",
    "\n",
    "def find_best_mask():\n",
    "    files = glob.glob(os.path.join(\"train\", \"*_mask.tif\"))\n",
    "    overall_mask = cv2.imread(files[0], cv2.IMREAD_GRAYSCALE)\n",
    "    overall_mask.fill(0)\n",
    "    overall_mask = overall_mask.astype(np.float32)\n",
    "\n",
    "    for fl in files:\n",
    "        mask = cv2.imread(fl, cv2.IMREAD_GRAYSCALE)\n",
    "        overall_mask += mask\n",
    "    overall_mask /= 255\n",
    "    max_value = overall_mask.max()\n",
    "    koeff = 0.5\n",
    "    overall_mask[overall_mask < koeff * max_value] = 0\n",
    "    overall_mask[overall_mask >= koeff * max_value] = 255\n",
    "    overall_mask = overall_mask.astype(np.uint8)\n",
    "    return overall_mask\n",
    "\n",
    "\n",
    "def create_submission(predictions, test_id, info):\n",
    "    sub_file = os.path.join('submission_' + info + '_' + str(datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")) + '.csv')\n",
    "    subm = open(sub_file, \"w\")\n",
    "    mask = find_best_mask()\n",
    "    encode = rle_encode(mask)\n",
    "    subm.write(\"img,pixels\\n\")\n",
    "    for i in range(len(test_id)):\n",
    "        subm.write(str(test_id[i]) + ',')\n",
    "        if predictions[i][1] > 0.5:\n",
    "            subm.write(encode)\n",
    "        subm.write('\\n')\n",
    "    subm.close()\n",
    "\n",
    "\n",
    "def get_empty_mask_state(mask):\n",
    "    out = []\n",
    "    for i in range(len(mask)):\n",
    "        if mask[i].sum() == 0:\n",
    "            out.append(0)\n",
    "        else:\n",
    "            out.append(1)\n",
    "    return np.array(out)\n",
    "\n",
    "\n",
    "def read_and_normalize_train_data(img_rows, img_cols):\n",
    "    train_data, train_target, train_id = load_train(img_rows, img_cols)\n",
    "    train_data = np.array(train_data, dtype=np.uint8)\n",
    "    train_target = np.array(train_target, dtype=np.uint8)\n",
    "    train_data = train_data.reshape(train_data.shape[0], 1, img_rows, img_cols)\n",
    "    # Convert to 0 or 1\n",
    "    train_target = get_empty_mask_state(train_target)\n",
    "    train_target = np_utils.to_categorical(train_target, 2)\n",
    "    train_target = train_target.astype('uint8')\n",
    "    train_data = train_data.astype('float32')\n",
    "    train_data /= 255\n",
    "    print('Train shape:', train_data.shape)\n",
    "    print(train_data.shape[0], 'train samples')\n",
    "    return train_data, train_target, train_id\n",
    "\n",
    "\n",
    "def read_and_normalize_test_data(img_rows, img_cols):\n",
    "    test_data, test_id = load_test(img_rows, img_cols)\n",
    "    test_data = np.array(test_data, dtype=np.uint8)\n",
    "    test_data = test_data.reshape(test_data.shape[0], 1, img_rows, img_cols)\n",
    "    test_data = test_data.astype('float32')\n",
    "    test_data /= 255\n",
    "    print('Test shape:', test_data.shape)\n",
    "    print(test_data.shape[0], 'test samples')\n",
    "    return test_data, test_id\n",
    "\n",
    "\n",
    "def merge_several_folds_mean(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a += np.array(data[i])\n",
    "    a /= nfolds\n",
    "    return a.tolist()\n",
    "\n",
    "\n",
    "def create_model(img_rows, img_cols):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dropout(0.25, input_shape=(1, img_rows, img_cols)))\n",
    "    \n",
    "    model.add(Convolution2D(32, 9, 9, border_mode='same', subsample=(2, 2), W_regularizer=l2(0.005)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Convolution2D(64, 7, 7, border_mode='same', subsample=(2, 2), W_regularizer=l2(0.005)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    \n",
    "    #model.add(Convolution2D(16, 3, 3, border_mode='same'))\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(Convolution2D(16, 3, 3, border_mode='same'))\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.5))\n",
    "#\n",
    "    #model.add(Convolution2D(32, 3, 3, border_mode='same'))\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(Convolution2D(32, 3, 3, border_mode='same'))\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #\n",
    "    model.add(Flatten())\n",
    "    model.add(MaxoutDense(128, W_regularizer=l2(0.003)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    opt = SGD(0.02, 0.95, decay = 0.003, nesterov=True)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_validation_predictions(train_data, predictions_valid):\n",
    "    pv = []\n",
    "    for i in range(len(train_data)):\n",
    "        pv.append(predictions_valid[i])\n",
    "    return pv\n",
    "\n",
    "\n",
    "def getPredScorePercent(train_target, predictions_valid):\n",
    "    perc = 0\n",
    "    for i in range(len(train_target)):\n",
    "        pred = 1\n",
    "        if predictions_valid[i][0] > 0.5:\n",
    "            pred = 0\n",
    "        real = 1\n",
    "        if train_target[i][0] > 0.5:\n",
    "            real = 0\n",
    "        if real == pred:\n",
    "            perc += 1\n",
    "    perc /= len(train_target)\n",
    "    return perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'object' (pos 1) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cd3317a04602>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_normalize_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_normalize_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-8e1171d4fc89>\u001b[0m in \u001b[0;36mread_and_normalize_train_data\u001b[1;34m(img_rows, img_cols)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_and_normalize_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mtrain_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-8e1171d4fc89>\u001b[0m in \u001b[0;36mload_train\u001b[1;34m(img_rows, img_cols)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mX_train_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mmask_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Required argument 'object' (pos 1) not found"
     ]
    }
   ],
   "source": [
    "train_data, train_target, train_id = read_and_normalize_train_data(img_rows, img_cols)\n",
    "test_data, test_id = read_and_normalize_test_data(img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_epoch = 100\n",
    "random_state = 51\n",
    "yfull_train = dict()\n",
    "yfull_test = []\n",
    "kf = KFold(len(train_data), n_folds=nfolds, shuffle=True, random_state=random_state)\n",
    "num_fold = 0\n",
    "sum_score = 0\n",
    "for train_index, test_index in kf:\n",
    "    model = create_model(img_rows, img_cols)\n",
    "    X_train, X_valid = train_data[train_index], train_data[test_index]\n",
    "    Y_train, Y_valid = train_target[train_index], train_target[test_index]\n",
    "    num_fold += 1\n",
    "    print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "    print('Split train: ', len(X_train), len(Y_train))\n",
    "    print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "    remote = RemoteMonitor(root='http://localhost:9000')\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          shuffle=True, verbose=1, validation_data=(X_valid, Y_valid), callbacks=[remote])\n",
    "    predictions_valid = model.predict(X_valid, batch_size=batch_size, verbose=1)\n",
    "    score = log_loss(Y_valid, predictions_valid)\n",
    "    print('Score log_loss: ', score)\n",
    "    # Store valid predictions\n",
    "    for i in range(len(test_index)):\n",
    "        yfull_train[test_index[i]] = predictions_valid[i]\n",
    "    # Store test predictions\n",
    "    test_prediction = model.predict(test_data, batch_size=batch_size, verbose=2)\n",
    "    yfull_test.append(test_prediction)\n",
    "\n",
    "predictions_valid = get_validation_predictions(train_data, yfull_train)\n",
    "score = log_loss(train_target, predictions_valid)\n",
    "print(\"Log_loss train independent avg: \", score)\n",
    "print('Final log_loss: {}, rows: {} cols: {} nfolds: {} epoch: {}'.format(score, img_rows, img_cols, nfolds, nb_epoch))\n",
    "perc = getPredScorePercent(train_target, train_id, predictions_valid)\n",
    "print('Percent success: {}'.format(perc))\n",
    "info_string = 'loss_' + str(score) \\\n",
    "                + '_r_' + str(img_rows) \\\n",
    "                + '_c_' + str(img_cols) \\\n",
    "                + '_folds_' + str(nfolds) \\\n",
    "                + '_ep_' + str(nb_epoch)\n",
    "test_res = merge_several_folds_mean(yfull_test, nfolds)\n",
    "create_submission(test_res, test_id, info_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 50\n",
    "model = create_model(img_rows, img_cols)\n",
    "remote = RemoteMonitor(root='http://localhost:9000')\n",
    "model.fit(train_data, train_target, batch_size=batch_size,\n",
    "          nb_epoch=nb_epoch,shuffle=True, verbose=1,\n",
    "          validation_data=(train_data[-500:], train_target[-500:]),\n",
    "          callbacks=[remote])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '2',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '3',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '4',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(map(lambda s: s.split('_')[0], train_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
