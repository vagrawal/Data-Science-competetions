{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu0 is not available  (error: Unable to get the number of gpus available: unknown error)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "__author__ = 'Ravi: https://kaggle.com/company'\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import datetime\n",
    "import time\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "def get_im_cv2(path, img_rows, img_cols):\n",
    "    img = cv2.imread(path, 0)\n",
    "    resized = cv2.resize(img, (img_cols, img_rows), cv2.INTER_LINEAR)\n",
    "    return resized\n",
    "\n",
    "\n",
    "def load_train(img_rows, img_cols):\n",
    "    X_train = []\n",
    "    X_train_id = []\n",
    "    mask_train = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Read train images')\n",
    "    files = glob.glob(\"train/*[0-9].tif\")\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = get_im_cv2(fl, img_rows, img_cols)\n",
    "        X_train.append(img)\n",
    "        X_train_id.append(flbase[:-4])\n",
    "        mask_path = \"train/\" + flbase[:-4] + \"_mask.tif\"\n",
    "        mask = get_im_cv2(mask_path, img_rows, img_cols)\n",
    "        mask_train.append(mask)\n",
    "\n",
    "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_train, mask_train, X_train_id\n",
    "\n",
    "\n",
    "def load_test(img_rows, img_cols):\n",
    "    print('Read test images')\n",
    "    files = glob.glob(\"test/*[0-9].tif\")\n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = get_im_cv2(fl, img_rows, img_cols)\n",
    "        X_test.append(img)\n",
    "        X_test_id.append(flbase[:-4])\n",
    "        total += 1\n",
    "\n",
    "    print('Read test data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_test, X_test_id\n",
    "\n",
    "\n",
    "def rle_encode(img, order='F'):\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []\n",
    "    r = 0\n",
    "    pos = 1\n",
    "    for c in bytes:\n",
    "        if c == 0:\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "\n",
    "    z = ''\n",
    "    for rr in runs:\n",
    "        z += str(rr[0]) + ' ' + str(rr[1]) + ' '\n",
    "    return z[:-1]\n",
    "\n",
    "\n",
    "def find_best_mask():\n",
    "    files = glob.glob(os.path.join(\"train\", \"*_mask.tif\"))\n",
    "    overall_mask = cv2.imread(files[0], cv2.IMREAD_GRAYSCALE)\n",
    "    overall_mask.fill(0)\n",
    "    overall_mask = overall_mask.astype(np.float32)\n",
    "\n",
    "    for fl in files:\n",
    "        mask = cv2.imread(fl, cv2.IMREAD_GRAYSCALE)\n",
    "        overall_mask += mask\n",
    "    overall_mask /= 255\n",
    "    max_value = overall_mask.max()\n",
    "    koeff = 0.5\n",
    "    overall_mask[overall_mask < koeff * max_value] = 0\n",
    "    overall_mask[overall_mask >= koeff * max_value] = 255\n",
    "    overall_mask = overall_mask.astype(np.uint8)\n",
    "    return overall_mask\n",
    "\n",
    "\n",
    "def create_submission(predictions, test_id, info):\n",
    "    sub_file = os.path.join('submission_' + info + '_' + str(datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")) + '.csv')\n",
    "    subm = open(sub_file, \"w\")\n",
    "    mask = find_best_mask()\n",
    "    encode = rle_encode(mask)\n",
    "    subm.write(\"img,pixels\\n\")\n",
    "    for i in range(len(test_id)):\n",
    "        subm.write(str(test_id[i]) + ',')\n",
    "        if predictions[i][1] > 0.5:\n",
    "            subm.write(encode)\n",
    "        subm.write('\\n')\n",
    "    subm.close()\n",
    "\n",
    "\n",
    "def get_empty_mask_state(mask):\n",
    "    out = []\n",
    "    for i in range(len(mask)):\n",
    "        if mask[i].sum() == 0:\n",
    "            out.append(0)\n",
    "        else:\n",
    "            out.append(1)\n",
    "    return np.array(out)\n",
    "\n",
    "\n",
    "def read_and_normalize_train_data(img_rows, img_cols):\n",
    "    train_data, train_target, train_id = load_train(img_rows, img_cols)\n",
    "    train_data = np.array(train_data, dtype=np.uint8)\n",
    "    train_target = np.array(train_target, dtype=np.uint8)\n",
    "    train_data = train_data.reshape(train_data.shape[0], 1, img_rows, img_cols)\n",
    "    # Convert to 0 or 1\n",
    "    train_target = get_empty_mask_state(train_target)\n",
    "    train_target = np_utils.to_categorical(train_target, 2)\n",
    "    train_data = train_data.astype('float32')\n",
    "    train_data /= 255\n",
    "    print('Train shape:', train_data.shape)\n",
    "    print(train_data.shape[0], 'train samples')\n",
    "    return train_data, train_target, train_id\n",
    "\n",
    "\n",
    "def read_and_normalize_test_data(img_rows, img_cols):\n",
    "    test_data, test_id = load_test(img_rows, img_cols)\n",
    "    test_data = np.array(test_data, dtype=np.uint8)\n",
    "    test_data = test_data.reshape(test_data.shape[0], 1, img_rows, img_cols)\n",
    "    test_data = test_data.astype('float32')\n",
    "    test_data /= 255\n",
    "    print('Test shape:', test_data.shape)\n",
    "    print(test_data.shape[0], 'test samples')\n",
    "    return test_data, test_id\n",
    "\n",
    "\n",
    "def merge_several_folds_mean(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a += np.array(data[i])\n",
    "    a /= nfolds\n",
    "    return a.tolist()\n",
    "\n",
    "\n",
    "def create_model(img_rows, img_cols):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Convolution2D(32, 7, 7, border_mode='same', subsample = (2, 2), input_shape=(1, img_rows, img_cols)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Convolution2D(64, 7, 7, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    " \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_validation_predictions(train_data, predictions_valid):\n",
    "    pv = []\n",
    "    for i in range(len(train_data)):\n",
    "        pv.append(predictions_valid[i])\n",
    "    return pv\n",
    "\n",
    "\n",
    "def getPredScorePercent(train_target, train_id, predictions_valid):\n",
    "    perc = 0\n",
    "    for i in range(len(train_target)):\n",
    "        pred = 1\n",
    "        if predictions_valid[i][0] > 0.5:\n",
    "            pred = 0\n",
    "        real = 1\n",
    "        if train_target[i][0] > 0.5:\n",
    "            real = 0\n",
    "        if real == pred:\n",
    "            perc += 1\n",
    "    perc /= len(train_target)\n",
    "    return perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train images\n",
      "Read train data time: 50.94 seconds\n",
      "Train shape: (5635, 1, 128, 128)\n",
      "5635 train samples\n",
      "Read test images\n",
      "Read test data time: 37.06 seconds\n",
      "Test shape: (5508, 1, 128, 128)\n",
      "5508 test samples\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 128, 128\n",
    "train_data, train_target, train_id = read_and_normalize_train_data(img_rows, img_cols)\n",
    "test_data, test_id = read_and_normalize_test_data(img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "The first layer in a Sequential model must get an `input_shape` or `batch_input_shape` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-41afbd9810be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0msum_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-d9c83e62bfc3>\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(img_rows, img_cols)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[1;31m# create an input layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'batch_input_shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                     raise Exception('The first layer in a Sequential model must '\n\u001b[0m\u001b[0;32m    106\u001b[0m                                     \u001b[1;34m'get an `input_shape` or '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m                                     '`batch_input_shape` argument.')\n",
      "\u001b[1;31mException\u001b[0m: The first layer in a Sequential model must get an `input_shape` or `batch_input_shape` argument."
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 50\n",
    "random_state = 51\n",
    "nfolds = 5\n",
    "\n",
    "yfull_train = dict()\n",
    "yfull_test = []\n",
    "kf = KFold(len(train_data), n_folds=nfolds, shuffle=True, random_state=random_state)\n",
    "num_fold = 0\n",
    "sum_score = 0\n",
    "for train_index, test_index in kf:\n",
    "    model = create_model(img_rows, img_cols)\n",
    "    X_train, X_valid = train_data[train_index], train_data[test_index]\n",
    "    Y_train, Y_valid = train_target[train_index], train_target[test_index]\n",
    "    num_fold += 1\n",
    "    print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "    print('Split train: ', len(X_train), len(Y_train))\n",
    "    print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=7, verbose=0),\n",
    "    ]\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          shuffle=True, verbose=1, validation_data=(X_valid, Y_valid))\n",
    "          #callbacks=callbacks)\n",
    "    predictions_valid = model.predict(X_valid, batch_size=batch_size, verbose=1)\n",
    "    score = log_loss(Y_valid, predictions_valid)\n",
    "    print('Score log_loss: ', score)\n",
    "    # Store valid predictions\n",
    "    for i in range(len(test_index)):\n",
    "        yfull_train[test_index[i]] = predictions_valid[i]\n",
    "    # Store test predictions\n",
    "    test_prediction = model.predict(test_data, batch_size=batch_size, verbose=2)\n",
    "    yfull_test.append(test_prediction)\n",
    "predictions_valid = get_validation_predictions(train_data, yfull_train)\n",
    "score = log_loss(train_target, predictions_valid)\n",
    "print(\"Log_loss train independent avg: \", score)\n",
    "print('Final log_loss: {}, rows: {} cols: {} nfolds: {} epoch: {}'.format(score, img_rows, img_cols, nfolds, nb_epoch))\n",
    "perc = getPredScorePercent(train_target, train_id, predictions_valid)\n",
    "print('Percent success: {}'.format(perc))\n",
    "info_string = 'loss_' + str(score) \\\n",
    "                + '_r_' + str(img_rows) \\\n",
    "                + '_c_' + str(img_cols) \\\n",
    "                + '_folds_' + str(nfolds) \\\n",
    "                + '_ep_' + str(nb_epoch)\n",
    "test_res = merge_several_folds_mean(yfull_test, nfolds)\n",
    "create_submission(test_res, test_id, info_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-453628521f78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_index' is not defined"
     ]
    }
   ],
   "source": [
    "train_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
